{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37676f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db2df5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset definition\n",
    "class myDataset(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self,root,transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"imgs\"))))\n",
    "\n",
    "\n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx -1\n",
    "        img_path = os.path.join(self.root, \"imgs\", self.imgs[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        self.data = open(os.path.join(self.root, \"annotations.csv\"))\n",
    "        data = csv.reader(self.data)\n",
    "        \n",
    "        boxes = []\n",
    "        row = data.__next__()\n",
    "        \n",
    "        for x in range(idx+1):\n",
    "            row = data.__next__()\n",
    "        \n",
    "        x1 = int(row[1])\n",
    "        y1 = int(row[2])\n",
    "        x2 = int(row[3])\n",
    "        y2 = int(row[4])\n",
    "        label = int(row[5])\n",
    "        boxes.append([x1, y1, x2, y2])\n",
    "        \n",
    "        self.data.close()\n",
    "        \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor([label], dtype=torch.int64)\n",
    "        \n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34937421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detection.transforms as T\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.PILToTensor())\n",
    "    transforms.append(T.Normalize())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4e7a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37e33dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b17e1d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = myDataset('db_lisa_tiny', get_transform(train=True))\n",
    "dataset_test = myDataset('db_lisa_tiny', get_transform(train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c152bc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "267ec364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detection.utils as utils\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=2,collate_fn=utils.collate_fn)\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=1,collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfb9853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a99a8503",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fb5919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c00a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=3,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eed341c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "debeb4db",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 20508) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32md:\\Programmieren\\PyTorch\\pytorch_venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1011\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1011\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1012\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Programmieren\\PyTorch\\LearningAndSoftComputing\\LearningAndSoftComputing\\Real_taketwo.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programmieren/PyTorch/LearningAndSoftComputing/LearningAndSoftComputing/Real_taketwo.ipynb#ch0000013?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdetection\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m train_one_epoch, evaluate\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programmieren/PyTorch/LearningAndSoftComputing/LearningAndSoftComputing/Real_taketwo.ipynb#ch0000013?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programmieren/PyTorch/LearningAndSoftComputing/LearningAndSoftComputing/Real_taketwo.ipynb#ch0000013?line=3'>4</a>\u001b[0m         \u001b[39m# train for one epoch, printing every 10 iterations\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Programmieren/PyTorch/LearningAndSoftComputing/LearningAndSoftComputing/Real_taketwo.ipynb#ch0000013?line=4'>5</a>\u001b[0m         train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programmieren/PyTorch/LearningAndSoftComputing/LearningAndSoftComputing/Real_taketwo.ipynb#ch0000013?line=5'>6</a>\u001b[0m         \u001b[39m# update the learning rate\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programmieren/PyTorch/LearningAndSoftComputing/LearningAndSoftComputing/Real_taketwo.ipynb#ch0000013?line=6'>7</a>\u001b[0m         lr_scheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\Programmieren\\PyTorch\\LearningAndSoftComputing\\LearningAndSoftComputing\\detection\\engine.py:27\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, optimizer, data_loader, device, epoch, print_freq, scaler)\u001b[0m\n\u001b[0;32m     21\u001b[0m     warmup_iters \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39m1000\u001b[39m, \u001b[39mlen\u001b[39m(data_loader) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     23\u001b[0m     lr_scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mLinearLR(\n\u001b[0;32m     24\u001b[0m         optimizer, start_factor\u001b[39m=\u001b[39mwarmup_factor, total_iters\u001b[39m=\u001b[39mwarmup_iters\n\u001b[0;32m     25\u001b[0m     )\n\u001b[1;32m---> 27\u001b[0m \u001b[39mfor\u001b[39;00m images, targets \u001b[39min\u001b[39;00m metric_logger\u001b[39m.\u001b[39mlog_every(data_loader, print_freq, header):\n\u001b[0;32m     28\u001b[0m     images \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(image\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m images)\n\u001b[0;32m     29\u001b[0m     targets \u001b[39m=\u001b[39m [{k: v\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m t\u001b[39m.\u001b[39mitems()} \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m targets]\n",
      "File \u001b[1;32md:\\Programmieren\\PyTorch\\LearningAndSoftComputing\\LearningAndSoftComputing\\detection\\utils.py:171\u001b[0m, in \u001b[0;36mMetricLogger.log_every\u001b[1;34m(self, iterable, print_freq, header)\u001b[0m\n\u001b[0;32m    167\u001b[0m     log_msg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelimiter\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m    168\u001b[0m         [header, \u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m space_fmt \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m}/\u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39meta: \u001b[39m\u001b[39m{eta}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m{meters}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtime: \u001b[39m\u001b[39m{time}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdata: \u001b[39m\u001b[39m{data}\u001b[39;00m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    169\u001b[0m     )\n\u001b[0;32m    170\u001b[0m MB \u001b[39m=\u001b[39m \u001b[39m1024.0\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024.0\u001b[39m\n\u001b[1;32m--> 171\u001b[0m \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m    172\u001b[0m     data_time\u001b[39m.\u001b[39mupdate(time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m end)\n\u001b[0;32m    173\u001b[0m     \u001b[39myield\u001b[39;00m obj\n",
      "File \u001b[1;32md:\\Programmieren\\PyTorch\\pytorch_venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Programmieren\\PyTorch\\pytorch_venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1207\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1206\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1207\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1209\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1210\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32md:\\Programmieren\\PyTorch\\pytorch_venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1173\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1169\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1171\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1172\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 1173\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1174\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1175\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32md:\\Programmieren\\PyTorch\\pytorch_venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1024\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1022\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1023\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1024\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(pids_str)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[0;32m   1026\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 20508) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "from detection.engine import train_one_epoch, evaluate\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "        # train for one epoch, printing every 10 iterations\n",
    "        train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "        # update the learning rate\n",
    "        lr_scheduler.step()\n",
    "        # evaluate on the test dataset\n",
    "        evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d367c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"model_real_fasterrcnn_mobilenet_v3_large_fpn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a8198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedModel = torch.load(\"model_real_fasterrcnn_mobilenet_v3_large_fpn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e23ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedModel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41843c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, targets = next(iter(data_loader_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedModel(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2803ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = img[3]\n",
    "imgs = np.transpose(imgs, (1,2,0)) #tt = np.transpose(tt,(1,2,0))\n",
    "plt.figure()\n",
    "plt.imshow(imgs)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a3ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c4da09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc39b81d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a23925d5e7df8fc0af1db509c5f92e14b8a3bef473598463d00740147b109ce2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
